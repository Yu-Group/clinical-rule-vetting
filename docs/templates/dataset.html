<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>rulevetting.templates.dataset API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>rulevetting.templates.dataset</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from os.path import join as oj

import numpy as np
import os
import pandas as pd
import random
from abc import abstractmethod
from joblib import Memory
from typing import Dict

import rulevetting


class DatasetTemplate:
    &#34;&#34;&#34;Classes that use this template should be called &#34;Dataset&#34;
    All functions take **kwargs, so you can specify any judgement calls you aren&#39;t sure about with a kwarg flag.
    &#34;&#34;&#34;

    @abstractmethod
    def clean_data(self, data_path: str = rulevetting.DATA_PATH, **kwargs) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Convert the raw data files into a pandas dataframe.
        Dataframe keys should be reasonable (lowercase, underscore-separated).
        Data types should be reasonable.

        Params
        ------
        data_path: str, optional
            Path to all data files
        kwargs: dict
            Dictionary of hyperparameters specifying judgement calls

        Returns
        -------
        cleaned_data: pd.DataFrame
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def preprocess_data(self, cleaned_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Preprocess the data.
        Impute missing values.
        Scale/transform values.
        Should put the prediction target in a column named &#34;outcome&#34;

        Parameters
        ----------
        cleaned_data: pd.DataFrame
        kwargs: dict
            Dictionary of hyperparameters specifying judgement calls

        Returns
        -------
        preprocessed_data: pd.DataFrame
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def extract_features(self, preprocessed_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Extract features from preprocessed data
        All features should be binary


        Parameters
        ----------
        preprocessed_data: pd.DataFrame
        kwargs: dict
            Dictionary of hyperparameters specifying judgement calls

        Returns
        -------
        extracted_features: pd.DataFrame
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def split_data(self, preprocessed_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Split into 3 sets: training, tuning, testing
        Keep in mind any natural splits (e.g. hospitals).
        Ensure that there are positive points in all splits.

        Parameters
        ----------
        preprocessed_data
        kwargs: dict
            Dictionary of hyperparameters specifying judgement calls

        Returns
        -------
        df_train
        df_tune
        df_test
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def get_outcome_name(self) -&gt; str:
        &#34;&#34;&#34;Should return the name of the outcome we are predicting
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def get_dataset_id(self) -&gt; str:
        &#34;&#34;&#34;Should return the name of the dataset id (str)
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def get_meta_keys(self) -&gt; list:
        &#34;&#34;&#34;Return list of keys which should not be used in fitting but are still useful for analysis
        &#34;&#34;&#34;
        return NotImplemented

    def get_judgement_calls_dictionary(self) -&gt; Dict[str, Dict[str, list]]:
        &#34;&#34;&#34;Return dictionary of keyword arguments for each functions in the dataset class.
        Each key should be a string with the name of the arg.
        Each value should be a list of values, with the default value coming first.

        Example
        -------
        return {
            &#39;clean_data&#39;: {},
            &#39;preprocess_data&#39;: {
                &#39;imputation_strategy&#39;: [&#39;mean&#39;, &#39;median&#39;],  # first value is default
            },
            &#39;extract_features&#39;: {},
            &#39;split_data&#39;: {},
        }
        &#34;&#34;&#34;
        return NotImplemented

    def get_data(self, save_csvs: bool = False,
                 data_path: str = rulevetting.DATA_PATH,
                 load_csvs: bool = False) -&gt; (pd.DataFrame, pd.DataFrame, pd.DataFrame):
        &#34;&#34;&#34;Runs all the processing and returns the data.
        This method does not need to be overriden.

        Params
        ------
        save_csvs: bool, optional
            Whether to save csv files of the processed data
        data_path: str, optional
            Path to all data
        load_csvs: bool, optional
            Whether to skip all processing and load data directly from csvs

        Returns
        -------
        df_train
        df_tune
        df_test
        &#34;&#34;&#34;
        PROCESSED_PATH = oj(data_path, self.get_dataset_id(), &#39;processed&#39;)
        if load_csvs:
            return tuple([pd.read_csv(oj(PROCESSED_PATH, s), index_col=0)
                          for s in [&#39;train.csv&#39;, &#39;tune.csv&#39;, &#39;test.csv&#39;]])
        np.random.seed(0)
        random.seed(0)
        CACHE_PATH = oj(data_path, &#39;joblib_cache&#39;)
        cache = Memory(CACHE_PATH, verbose=0).cache
        kwargs = self.get_judgement_calls_dictionary()
        default_kwargs = {}
        for key in kwargs.keys():
            func_kwargs = kwargs[key]
            default_kwargs[key] = {k: func_kwargs[k][0] # first arg in each list is default
                                   for k in func_kwargs.keys()}

        print(&#39;kwargs&#39;, default_kwargs)
        cleaned_data = cache(self.clean_data)(data_path=data_path, **default_kwargs[&#39;clean_data&#39;])
        preprocessed_data = cache(self.preprocess_data)(cleaned_data, **default_kwargs[&#39;preprocess_data&#39;])
        extracted_features = cache(self.extract_features)(preprocessed_data, **default_kwargs[&#39;extract_features&#39;])
        df_train, df_tune, df_test = cache(self.split_data)(extracted_features, **default_kwargs[&#39;split_data&#39;])
        if save_csvs:
            os.makedirs(PROCESSED_PATH, exist_ok=True)
            for df, fname in zip([df_train, df_tune, df_test],
                                 [&#39;train.csv&#39;, &#39;tune.csv&#39;, &#39;test.csv&#39;]):
                meta_keys = rulevetting.api.util.get_feat_names_from_base_feats(df.keys(), self.get_meta_keys())
                df.loc[:, meta_keys].to_csv(oj(PROCESSED_PATH, f&#39;meta_{fname}&#39;))
                df.drop(columns=meta_keys).to_csv(oj(PROCESSED_PATH, fname))
        return df_train, df_tune, df_test</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="rulevetting.templates.dataset.DatasetTemplate"><code class="flex name class">
<span>class <span class="ident">DatasetTemplate</span></span>
</code></dt>
<dd>
<div class="desc"><p>Classes that use this template should be called "Dataset"
All functions take **kwargs, so you can specify any judgement calls you aren't sure about with a kwarg flag.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DatasetTemplate:
    &#34;&#34;&#34;Classes that use this template should be called &#34;Dataset&#34;
    All functions take **kwargs, so you can specify any judgement calls you aren&#39;t sure about with a kwarg flag.
    &#34;&#34;&#34;

    @abstractmethod
    def clean_data(self, data_path: str = rulevetting.DATA_PATH, **kwargs) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Convert the raw data files into a pandas dataframe.
        Dataframe keys should be reasonable (lowercase, underscore-separated).
        Data types should be reasonable.

        Params
        ------
        data_path: str, optional
            Path to all data files
        kwargs: dict
            Dictionary of hyperparameters specifying judgement calls

        Returns
        -------
        cleaned_data: pd.DataFrame
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def preprocess_data(self, cleaned_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Preprocess the data.
        Impute missing values.
        Scale/transform values.
        Should put the prediction target in a column named &#34;outcome&#34;

        Parameters
        ----------
        cleaned_data: pd.DataFrame
        kwargs: dict
            Dictionary of hyperparameters specifying judgement calls

        Returns
        -------
        preprocessed_data: pd.DataFrame
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def extract_features(self, preprocessed_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Extract features from preprocessed data
        All features should be binary


        Parameters
        ----------
        preprocessed_data: pd.DataFrame
        kwargs: dict
            Dictionary of hyperparameters specifying judgement calls

        Returns
        -------
        extracted_features: pd.DataFrame
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def split_data(self, preprocessed_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Split into 3 sets: training, tuning, testing
        Keep in mind any natural splits (e.g. hospitals).
        Ensure that there are positive points in all splits.

        Parameters
        ----------
        preprocessed_data
        kwargs: dict
            Dictionary of hyperparameters specifying judgement calls

        Returns
        -------
        df_train
        df_tune
        df_test
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def get_outcome_name(self) -&gt; str:
        &#34;&#34;&#34;Should return the name of the outcome we are predicting
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def get_dataset_id(self) -&gt; str:
        &#34;&#34;&#34;Should return the name of the dataset id (str)
        &#34;&#34;&#34;
        return NotImplemented

    @abstractmethod
    def get_meta_keys(self) -&gt; list:
        &#34;&#34;&#34;Return list of keys which should not be used in fitting but are still useful for analysis
        &#34;&#34;&#34;
        return NotImplemented

    def get_judgement_calls_dictionary(self) -&gt; Dict[str, Dict[str, list]]:
        &#34;&#34;&#34;Return dictionary of keyword arguments for each functions in the dataset class.
        Each key should be a string with the name of the arg.
        Each value should be a list of values, with the default value coming first.

        Example
        -------
        return {
            &#39;clean_data&#39;: {},
            &#39;preprocess_data&#39;: {
                &#39;imputation_strategy&#39;: [&#39;mean&#39;, &#39;median&#39;],  # first value is default
            },
            &#39;extract_features&#39;: {},
            &#39;split_data&#39;: {},
        }
        &#34;&#34;&#34;
        return NotImplemented

    def get_data(self, save_csvs: bool = False,
                 data_path: str = rulevetting.DATA_PATH,
                 load_csvs: bool = False) -&gt; (pd.DataFrame, pd.DataFrame, pd.DataFrame):
        &#34;&#34;&#34;Runs all the processing and returns the data.
        This method does not need to be overriden.

        Params
        ------
        save_csvs: bool, optional
            Whether to save csv files of the processed data
        data_path: str, optional
            Path to all data
        load_csvs: bool, optional
            Whether to skip all processing and load data directly from csvs

        Returns
        -------
        df_train
        df_tune
        df_test
        &#34;&#34;&#34;
        PROCESSED_PATH = oj(data_path, self.get_dataset_id(), &#39;processed&#39;)
        if load_csvs:
            return tuple([pd.read_csv(oj(PROCESSED_PATH, s), index_col=0)
                          for s in [&#39;train.csv&#39;, &#39;tune.csv&#39;, &#39;test.csv&#39;]])
        np.random.seed(0)
        random.seed(0)
        CACHE_PATH = oj(data_path, &#39;joblib_cache&#39;)
        cache = Memory(CACHE_PATH, verbose=0).cache
        kwargs = self.get_judgement_calls_dictionary()
        default_kwargs = {}
        for key in kwargs.keys():
            func_kwargs = kwargs[key]
            default_kwargs[key] = {k: func_kwargs[k][0] # first arg in each list is default
                                   for k in func_kwargs.keys()}

        print(&#39;kwargs&#39;, default_kwargs)
        cleaned_data = cache(self.clean_data)(data_path=data_path, **default_kwargs[&#39;clean_data&#39;])
        preprocessed_data = cache(self.preprocess_data)(cleaned_data, **default_kwargs[&#39;preprocess_data&#39;])
        extracted_features = cache(self.extract_features)(preprocessed_data, **default_kwargs[&#39;extract_features&#39;])
        df_train, df_tune, df_test = cache(self.split_data)(extracted_features, **default_kwargs[&#39;split_data&#39;])
        if save_csvs:
            os.makedirs(PROCESSED_PATH, exist_ok=True)
            for df, fname in zip([df_train, df_tune, df_test],
                                 [&#39;train.csv&#39;, &#39;tune.csv&#39;, &#39;test.csv&#39;]):
                meta_keys = rulevetting.api.util.get_feat_names_from_base_feats(df.keys(), self.get_meta_keys())
                df.loc[:, meta_keys].to_csv(oj(PROCESSED_PATH, f&#39;meta_{fname}&#39;))
                df.drop(columns=meta_keys).to_csv(oj(PROCESSED_PATH, fname))
        return df_train, df_tune, df_test</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="rulevetting.projects.iai_pecarn.dataset.Dataset" href="../projects/iai_pecarn/dataset.html#rulevetting.projects.iai_pecarn.dataset.Dataset">Dataset</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="rulevetting.templates.dataset.DatasetTemplate.clean_data"><code class="name flex">
<span>def <span class="ident">clean_data</span></span>(<span>self, data_path: str = '/Volumes/GoogleDrive/My Drive/research/rules/rule-vetting/data', **kwargs) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Convert the raw data files into a pandas dataframe.
Dataframe keys should be reasonable (lowercase, underscore-separated).
Data types should be reasonable.</p>
<h2 id="params">Params</h2>
<p>data_path: str, optional
Path to all data files
kwargs: dict
Dictionary of hyperparameters specifying judgement calls</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>cleaned_data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def clean_data(self, data_path: str = rulevetting.DATA_PATH, **kwargs) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Convert the raw data files into a pandas dataframe.
    Dataframe keys should be reasonable (lowercase, underscore-separated).
    Data types should be reasonable.

    Params
    ------
    data_path: str, optional
        Path to all data files
    kwargs: dict
        Dictionary of hyperparameters specifying judgement calls

    Returns
    -------
    cleaned_data: pd.DataFrame
    &#34;&#34;&#34;
    return NotImplemented</code></pre>
</details>
</dd>
<dt id="rulevetting.templates.dataset.DatasetTemplate.extract_features"><code class="name flex">
<span>def <span class="ident">extract_features</span></span>(<span>self, preprocessed_data: pandas.core.frame.DataFrame, **kwargs) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Extract features from preprocessed data
All features should be binary</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>preprocessed_data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of hyperparameters specifying judgement calls</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>extracted_features</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def extract_features(self, preprocessed_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Extract features from preprocessed data
    All features should be binary


    Parameters
    ----------
    preprocessed_data: pd.DataFrame
    kwargs: dict
        Dictionary of hyperparameters specifying judgement calls

    Returns
    -------
    extracted_features: pd.DataFrame
    &#34;&#34;&#34;
    return NotImplemented</code></pre>
</details>
</dd>
<dt id="rulevetting.templates.dataset.DatasetTemplate.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>self, save_csvs: bool = False, data_path: str = '/Volumes/GoogleDrive/My Drive/research/rules/rule-vetting/data', load_csvs: bool = False) ‑> (<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Runs all the processing and returns the data.
This method does not need to be overriden.</p>
<h2 id="params">Params</h2>
<p>save_csvs: bool, optional
Whether to save csv files of the processed data
data_path: str, optional
Path to all data
load_csvs: bool, optional
Whether to skip all processing and load data directly from csvs</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>df_train</code></dt>
<dd>&nbsp;</dd>
<dt><code>df_tune</code></dt>
<dd>&nbsp;</dd>
<dt><code>df_test</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data(self, save_csvs: bool = False,
             data_path: str = rulevetting.DATA_PATH,
             load_csvs: bool = False) -&gt; (pd.DataFrame, pd.DataFrame, pd.DataFrame):
    &#34;&#34;&#34;Runs all the processing and returns the data.
    This method does not need to be overriden.

    Params
    ------
    save_csvs: bool, optional
        Whether to save csv files of the processed data
    data_path: str, optional
        Path to all data
    load_csvs: bool, optional
        Whether to skip all processing and load data directly from csvs

    Returns
    -------
    df_train
    df_tune
    df_test
    &#34;&#34;&#34;
    PROCESSED_PATH = oj(data_path, self.get_dataset_id(), &#39;processed&#39;)
    if load_csvs:
        return tuple([pd.read_csv(oj(PROCESSED_PATH, s), index_col=0)
                      for s in [&#39;train.csv&#39;, &#39;tune.csv&#39;, &#39;test.csv&#39;]])
    np.random.seed(0)
    random.seed(0)
    CACHE_PATH = oj(data_path, &#39;joblib_cache&#39;)
    cache = Memory(CACHE_PATH, verbose=0).cache
    kwargs = self.get_judgement_calls_dictionary()
    default_kwargs = {}
    for key in kwargs.keys():
        func_kwargs = kwargs[key]
        default_kwargs[key] = {k: func_kwargs[k][0] # first arg in each list is default
                               for k in func_kwargs.keys()}

    print(&#39;kwargs&#39;, default_kwargs)
    cleaned_data = cache(self.clean_data)(data_path=data_path, **default_kwargs[&#39;clean_data&#39;])
    preprocessed_data = cache(self.preprocess_data)(cleaned_data, **default_kwargs[&#39;preprocess_data&#39;])
    extracted_features = cache(self.extract_features)(preprocessed_data, **default_kwargs[&#39;extract_features&#39;])
    df_train, df_tune, df_test = cache(self.split_data)(extracted_features, **default_kwargs[&#39;split_data&#39;])
    if save_csvs:
        os.makedirs(PROCESSED_PATH, exist_ok=True)
        for df, fname in zip([df_train, df_tune, df_test],
                             [&#39;train.csv&#39;, &#39;tune.csv&#39;, &#39;test.csv&#39;]):
            meta_keys = rulevetting.api.util.get_feat_names_from_base_feats(df.keys(), self.get_meta_keys())
            df.loc[:, meta_keys].to_csv(oj(PROCESSED_PATH, f&#39;meta_{fname}&#39;))
            df.drop(columns=meta_keys).to_csv(oj(PROCESSED_PATH, fname))
    return df_train, df_tune, df_test</code></pre>
</details>
</dd>
<dt id="rulevetting.templates.dataset.DatasetTemplate.get_dataset_id"><code class="name flex">
<span>def <span class="ident">get_dataset_id</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Should return the name of the dataset id (str)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def get_dataset_id(self) -&gt; str:
    &#34;&#34;&#34;Should return the name of the dataset id (str)
    &#34;&#34;&#34;
    return NotImplemented</code></pre>
</details>
</dd>
<dt id="rulevetting.templates.dataset.DatasetTemplate.get_judgement_calls_dictionary"><code class="name flex">
<span>def <span class="ident">get_judgement_calls_dictionary</span></span>(<span>self) ‑> Dict[str, Dict[str, list]]</span>
</code></dt>
<dd>
<div class="desc"><p>Return dictionary of keyword arguments for each functions in the dataset class.
Each key should be a string with the name of the arg.
Each value should be a list of values, with the default value coming first.</p>
<h2 id="example">Example</h2>
<p>return {
'clean_data': {},
'preprocess_data': {
'imputation_strategy': ['mean', 'median'],
# first value is default
},
'extract_features': {},
'split_data': {},
}</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_judgement_calls_dictionary(self) -&gt; Dict[str, Dict[str, list]]:
    &#34;&#34;&#34;Return dictionary of keyword arguments for each functions in the dataset class.
    Each key should be a string with the name of the arg.
    Each value should be a list of values, with the default value coming first.

    Example
    -------
    return {
        &#39;clean_data&#39;: {},
        &#39;preprocess_data&#39;: {
            &#39;imputation_strategy&#39;: [&#39;mean&#39;, &#39;median&#39;],  # first value is default
        },
        &#39;extract_features&#39;: {},
        &#39;split_data&#39;: {},
    }
    &#34;&#34;&#34;
    return NotImplemented</code></pre>
</details>
</dd>
<dt id="rulevetting.templates.dataset.DatasetTemplate.get_meta_keys"><code class="name flex">
<span>def <span class="ident">get_meta_keys</span></span>(<span>self) ‑> list</span>
</code></dt>
<dd>
<div class="desc"><p>Return list of keys which should not be used in fitting but are still useful for analysis</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def get_meta_keys(self) -&gt; list:
    &#34;&#34;&#34;Return list of keys which should not be used in fitting but are still useful for analysis
    &#34;&#34;&#34;
    return NotImplemented</code></pre>
</details>
</dd>
<dt id="rulevetting.templates.dataset.DatasetTemplate.get_outcome_name"><code class="name flex">
<span>def <span class="ident">get_outcome_name</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Should return the name of the outcome we are predicting</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def get_outcome_name(self) -&gt; str:
    &#34;&#34;&#34;Should return the name of the outcome we are predicting
    &#34;&#34;&#34;
    return NotImplemented</code></pre>
</details>
</dd>
<dt id="rulevetting.templates.dataset.DatasetTemplate.preprocess_data"><code class="name flex">
<span>def <span class="ident">preprocess_data</span></span>(<span>self, cleaned_data: pandas.core.frame.DataFrame, **kwargs) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Preprocess the data.
Impute missing values.
Scale/transform values.
Should put the prediction target in a column named "outcome"</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cleaned_data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of hyperparameters specifying judgement calls</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>preprocessed_data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def preprocess_data(self, cleaned_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Preprocess the data.
    Impute missing values.
    Scale/transform values.
    Should put the prediction target in a column named &#34;outcome&#34;

    Parameters
    ----------
    cleaned_data: pd.DataFrame
    kwargs: dict
        Dictionary of hyperparameters specifying judgement calls

    Returns
    -------
    preprocessed_data: pd.DataFrame
    &#34;&#34;&#34;
    return NotImplemented</code></pre>
</details>
</dd>
<dt id="rulevetting.templates.dataset.DatasetTemplate.split_data"><code class="name flex">
<span>def <span class="ident">split_data</span></span>(<span>self, preprocessed_data: pandas.core.frame.DataFrame, **kwargs) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Split into 3 sets: training, tuning, testing
Keep in mind any natural splits (e.g. hospitals).
Ensure that there are positive points in all splits.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>preprocessed_data</code></strong></dt>
<dd>&nbsp;</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of hyperparameters specifying judgement calls</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>df_train</code></dt>
<dd>&nbsp;</dd>
<dt><code>df_tune</code></dt>
<dd>&nbsp;</dd>
<dt><code>df_test</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def split_data(self, preprocessed_data: pd.DataFrame, **kwargs) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Split into 3 sets: training, tuning, testing
    Keep in mind any natural splits (e.g. hospitals).
    Ensure that there are positive points in all splits.

    Parameters
    ----------
    preprocessed_data
    kwargs: dict
        Dictionary of hyperparameters specifying judgement calls

    Returns
    -------
    df_train
    df_tune
    df_test
    &#34;&#34;&#34;
    return NotImplemented</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="rulevetting.templates" href="index.html">rulevetting.templates</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="rulevetting.templates.dataset.DatasetTemplate" href="#rulevetting.templates.dataset.DatasetTemplate">DatasetTemplate</a></code></h4>
<ul class="">
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.clean_data" href="#rulevetting.templates.dataset.DatasetTemplate.clean_data">clean_data</a></code></li>
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.extract_features" href="#rulevetting.templates.dataset.DatasetTemplate.extract_features">extract_features</a></code></li>
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.get_data" href="#rulevetting.templates.dataset.DatasetTemplate.get_data">get_data</a></code></li>
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.get_dataset_id" href="#rulevetting.templates.dataset.DatasetTemplate.get_dataset_id">get_dataset_id</a></code></li>
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.get_judgement_calls_dictionary" href="#rulevetting.templates.dataset.DatasetTemplate.get_judgement_calls_dictionary">get_judgement_calls_dictionary</a></code></li>
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.get_meta_keys" href="#rulevetting.templates.dataset.DatasetTemplate.get_meta_keys">get_meta_keys</a></code></li>
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.get_outcome_name" href="#rulevetting.templates.dataset.DatasetTemplate.get_outcome_name">get_outcome_name</a></code></li>
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.preprocess_data" href="#rulevetting.templates.dataset.DatasetTemplate.preprocess_data">preprocess_data</a></code></li>
<li><code><a title="rulevetting.templates.dataset.DatasetTemplate.split_data" href="#rulevetting.templates.dataset.DatasetTemplate.split_data">split_data</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>